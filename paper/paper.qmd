---
title: "Predicting the 2024 US Presidential Election with a Model-Based Forecast"
subtitle: "Using Generalized Linear Models to Predict Election Outcomes"
author: 
  - Yuanyi (Leo) Liu
  - Dezhen Chen
  - Ziyuan Shen
thanks: "Code and data are available at: [Forecasting the 2024 US Presidential Election](https://github.com/leoyliu/Forecasting-the-2024-US-Presidential-Election)."
date: today
date-format: long
abstract: "In this paper, we built a linear regression model based on \"poll-of-polls\" data to predict the winner of the 2024 U.S. By combining data from multiple polls, our model can predict voter preferences more consistently and predict that Donald Trump is likely to win. This approach helps reduce the short-term variation present in individual polls and provides a clearer view of long-term electoral trends. Our findings contribute to understanding the dynamics of public opinion during election campaigns, which helps the public and political strategists make more informative decisions."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(dplyr)
library(here)
library(ggplot2)
library(kableExtra)
library(modelsummary)
library(rstanarm)
library(modelsummary)
library(arrow)
library(knitr)
library(kableExtra)
library(usmap)

```


# Introduction {#sec-intro}

The presidential election has a significant impact on national and global policies, which makes election forecasting a valuable tool for understanding political outcomes. However, individual polls often contain biases and short-term fluctuations that can obscure long-term trends. To deal with these challenges, we use a ‘poll-of-polls’ approach that combines multiple polls to provide more stable predictions of voter preferences over time. In this paper, we use national polling data from the period leading up to the 2024 U.S. presidential election to generate a logistic model that predicts the winner while capturing changes in public opinion throughout the election period.

The model estimates the probability of a candidate winning an election based on aggregated polling data. Logistic regression is used for binary outcomes such as election results, which allows us to model the likelihood of each candidate winning as new data becomes available. By taking into account changes in opinion polls and tracking trends in public opinion over time, this model improves the accuracy of predictions.

Our analysis identifies key trends among the major candidates and tracks changes in public sentiment throughout the campaign. The results suggest that aggregated polls can reduce some uncertainty by smoothing short-term fluctuations between surveys, but uncertainty cannot be eliminated. A sudden change in public opinion can still change the path of an election campaign, which highlights the importance of continuous polling monitoring.

A reliable election forecast can influence public expectations, and campaign strategies, and increase the visibility of reporting on election trends. An accurate forecast can also increase voter participation by providing individuals with a clearer perspective of the electoral landscape, and help them participate more effectively in the process of democracy. Prediction models like ours not only help with resource allocation for campaigns but also support the wider public by providing them with a clearer understanding of political dynamics.

The structure of the paper is organized as follows: following @sec-intro, @sec-data presents the data collection and cleaning process, along with an overview of the variables used in the analysis. @sec-model introduces the forecasting models, explaining why the selected models are suitable for predicting election outcomes based on aggregated polling data. Then @sec-result presents the main findings, including detailed crime trends for each neighborhood and year. Finally, @sec-discussion provides the results, highlighting key trends and predictions. Eventuallt, @sec-discussion concludes with a discussion of the findings, evaluating the reliability of the forecasts and identifying potential limitations of the models.


# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR] to process and analyze polling data for the 2024 U.S. Presidential election. The dataset used for this analysis was obtained from the FiveThirtyEight 2024 U.S. Presidential Election Polls [@citedata]. It consists of polling data for the 2024 general election, covering various polling organizations and methodologies. Following methodologies discussed by "Telling Stories with Data" [@tellingstories], we forecast election outcomes using the "poll of polls" method, which aggregates results from multiple polls to reduce bias and provide a more accurate representation of voter sentiment.

The dataset includes 15,891 rows and 52 columns, covering various pollster attributes such as pollster name, state, methodology, and polling results. To ensure the reliability of our analysis, we filter the data to include only polls with a numeric grade of 2.5 or higher, which represents high-quality, reputable pollsters. This filtering allows us to focus on polls that follow rigorous standards and have demonstrated transparency and accuracy.

Additionally, we limit the dataset to polls conducted after July 15, 2024, when Donald Trump officially announced his campaign, ensuring that the data reflects the most current public sentiment. Other similar datasets from prior elections, such as data from previous general election cycles, could have been used for comparison. However, given that this analysis focuses on the upcoming 2024 election and the shift in public opinion, the most relevant data is specific to the current cycle.

## Measurement

Polling data is a measurement of public sentiment captured through various survey methods. Polling organizations collect responses from individuals representing different segments of the population and ask them about their voting preferences. These responses are then weighted to reflect a more accurate representation of the electorate, based on factors like age, gender, race, and geographic region.

For this dataset, the poll results reflect the percentage of respondents who support a particular candidate. Different polling methods—such as live phone interviews, online panels, and mixed methodologies—capture this information. Each polling organization applies its own methodology, which can influence the results. For example, polls that use live interviews may experience different respondent behavior than those that use online surveys. More details on polling methodologies can be found in the [ABC News methodology explanation](https://abcnews.go.com/538/trump-leads-swing-state-polls-tied-biden-nationally/story?id=109506070).

The key measurement process involves converting real-world voter preferences into a dataset of percentages that reflect support for a candidate at a specific point in time. Polling organizations typically provide this data at a state or national level, which allows for both localized and broad interpretations of voter sentiment.

## Outcome variables

### Percent Support for Donald Trump (pct)
The primary outcome variable is the percentage (`pct`) of respondents who indicated support for Donald Trump in the 2024 general election. This percentage is calculated based on the total number of respondents in each poll divide by `sample_size`. The data includes observations from various states, providing both national and state-specific measures of Trump’s support.

```{r}
#| label: fig-trump-pct
#| fig-cap: "Donald Trump's polling percentages from July to October 2024. Each dot indicates the polling percentage for Trump on a specific date, while the blue line shows the trend in Trump's support."
#| echo: false
#| warning: false

cleaned_data <- read.csv(here::here("data/02-analysis_data/analysis_data.csv"))

cleaned_data <- cleaned_data %>%
  mutate(end_date = as.Date(end_date))  # Convert to Date format if not already

ggplot(cleaned_data, aes(x = end_date, y = pct)) +
  geom_point() +  # Add points for individual poll data
  scale_x_date(date_breaks = "1 month", date_labels = "%b %Y") +  # Show month and year, with one label per month
  labs(
    x = "Date of Poll",
    y = "Polling Percentage (%)",
  ) +
  theme_minimal() +  # Use a clean minimal theme
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),  # Center and adjust title size
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels for readability
  ) +
  geom_smooth()
```

@fig-trump-pct shows Donald Trump's polling percentages over time from July to October 2024. Each black dot represents an individual poll conducted on a specific date, indicating the percentage of voters who supported Trump in that poll. The blue line represents a trendline, smoothing out the individual poll results to show the general trajectory of Trump's support over time.

Initially, Trump's polling percentage appears stable with small fluctuations around 45%. However, as the campaign progresses into October, there is a slight upward trend in Trump's polling percentage, suggesting that his support increased as the election neared.

The shaded region around the blue line represents the confidence interval, indicating the range within which the true polling percentage is likely to fall, accounting for sampling variation.

## Predictor variables
Polling Methodology (methodology)
The `methodology` variable describes the method each pollster used to collect data. It includes approaches such as live phone interviews, online surveys, and mixed methods. For polls that used multiple collection methods (e.g., phone and online), we labeled them as "Mixed Voting" for simplicity. The methodology is important because different approaches can introduce varying degrees of bias, influencing the final reported percentages.

Placeholder for a table showing the distribution of polling methodologies across different states.

 State (state)
The `state` variable identifies whether the poll is state-specific or national. In state-specific polls, the data reflects localized voter preferences, while national polls aggregate opinions across the entire country. For this analysis, we ignore national polls and focus entirely on state polls because electoral outcomes are determined on a state-by-state basis in the U.S. election system.

Polling Score and Transparency (numeric_grade and transparency_score)
The `numeric_grade` variable is a rating assigned to each polling organization, indicating the reliability of the poll. Pollsters with higher numeric grades are considered more reliable and consistent in their methodology (e.g. higher than 2.5). Additionally, the `transparency_score` measures how openly a pollster shares their methodology and data, which further affects the trustworthiness of their results.

 Sample Size (sample_size)
The `sample_size` variable represents the total number of respondents surveyed in each poll. A larger sample size generally leads to more reliable and precise estimates of voter sentiment, as it reduces the margin of error. In contrast, smaller sample sizes can result in greater variability and less confidence in the results.

 Poll Duration (duration)
The `duration` variable is a constructed variable that represents how long Donald Trump has been in the 2024 presidential campaign, measured as the number of days from his official campaign announcement on July 15, 2024 until the `end_date` of each poll. This variable helps quantify how much time has passed since Trump officially entered the race and allows us to examine how his support has evolved over the course of his campaign.

In summary, the dataset offers a rich variety of variables that capture voter sentiment, pollster reliability, and electoral dynamics. By carefully filtering and analyzing this data, we can build a robust model to forecast the outcome of the 2024 US Presidential election.


# Model {#sec-model}
Our modeling approach aims to quantify the relationship between various polling metrics and the percentage support for a candidate. For this analysis, we use a linear model (LM) to examine how factors such as poll grade, methodology, poll duration, sample size, transparency score, and state influence support percentages. The model is implemented using the lm function, with a Gaussian distribution to capture the variability in support rates.

In this analysis, we use predictors that reflect both the methodological quality and structural characteristics of each poll. Specifically, we include variables such as numeric_grade, which quantifies the poll’s quality, methodology, duration (the length of the election period), sample_size, transparency_score, and state (the regional factor). This selection of predictors ensures a comprehensive view of the factors impacting support percentage.

The model assumes that the distribution of support percentage, given these polling characteristics, follows a normal distribution. This Gaussian assumption facilitates parameter estimation, which is a standard approach in linear regression. To prevent overfitting and ensure interpretability, we assume moderate priors, maintaining balanced uncertainty across our predictors. This approach enables us to assess the impact of polling characteristics on candidate support while ensuring stability and robustness in our findings.


## Model set-up
The model now predicts Trump's support percentage using the following predictor variables:

Numeric Grade (numeric_grade): Represents the quality rating of the poll.

Methodology (methodology): Different methods used to conduct the poll, such as live phone, mixed voting, or online ads.

Poll Duration (duration): The the length of the election period was conducted.

Sample Size (sample_size): The number of respondents in the poll.

Transparency Score (transparency_score): A measure of how transparent the polling data and methodology are.

State (state): A categorical variable representing the U.S. state where the poll was conducted.

The model takes the form:

\begin{align*}
    y_i \mid \mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\
    \mu_i &= \beta_0 + \beta_1 \cdot \text{numeric\_grade}_i + \beta_2 \cdot \text{methodology}_i \\
          &\quad + \beta_3 \cdot \text{duration}_i + \beta_4 \cdot \text{sample\_size}_i \\
          &\quad + \beta_5 \cdot \text{transparency\_score}_i + \beta_6 \cdot \text{state}_i + \epsilon_i \\
    \epsilon_i &\sim \text{Normal}(0, \sigma^2)
\end{align*}

\textbf{Where:}
\begin{itemize}
    \item $\beta_0$ is the intercept term.
    \item $\beta_1, \beta_2, \beta_3, \beta_4, \beta_5, \beta_6$ are the coefficients for each predictor.
    \item $\sigma^2$ is the variance of the error term.
\end{itemize}


The model is executed in R using the \texttt{rstanarm} package. Default priors from \texttt{rstanarm} are used, with the priors set to have a mean of zero and a moderate standard deviation to ensure a reasonable level of regularization.

### Model justification
Existing research and political science theories suggest that factors such as poll quality, sample size, transparency, methodology, poll duration, and the state where the poll takes place can significantly influence Trump's support percentage. Higher quality polls and larger sample sizes are believed to yield more reliable estimates, while transparency scores can affect levels of public trust, potentially altering support. Moreover, different polling methodologies (e.g., online surveys, telephone interviews) may affect how representative the sample is, while longer polling durations can reflect shifts in public sentiment over time. State-specific factors, such as local political events or population characteristics, can also contribute to the variation in support. The timing of the poll, particularly in relation to key political events, might further influence public opinion.

A linear regression model was chosen to predict Trump's support percentage because the dependent variable is continuous and tends to follow a normal distribution. Linear regression is a straightforward method to analyze how multiple factors contribute to an outcome, and it offers easy-to-interpret coefficients for each predictor. The model helps us determine the extent to which different aspects of polling influence the level of public support for Trump.
```{r}
#| label: tbl-summary-model
#| tbl-cap: Summary of the Linear Regression Model
#| echo: false
#| warning: false

model2 <- readRDS(file = here::here("models/first_model.rds"))

modelsummary(
  list(
    "Linear Model" = model2
  ),
  statistic = NULL 
)
```

Further justification for using this model comes from its alignment with the central limit theorem, which suggests that with sufficient sample size, the distribution of poll percentages should approximate normality. Additionally, the relationships between the predictors (e.g., poll quality, methodology type) and support align well with established theories in political behavior, giving a solid theoretical underpinning to our model. The simplicity of a linear regression approach also helps mitigate overfitting, ensuring our results are generalizable to a broader set of polling data. The model assumptions, including linearity, independence, and normality of residuals, are adequately satisfied by our dataset, making this approach not only convenient but also statistically robust for our analysis.


# Results {#sec-result}
## Model Results and Interpretation
The linear regression model, using 384 data points, estimated the factors influencing Trump's support levels. The intercept, estimated at 43.39, represents the level of support when all other predictors are at baseline.The model achieved an R-squared value of 0.85, indicating that 85% of the variance in Trump's support percentage can be explained by the predictors included in the model. The adjusted R-squared value of 0.82 also shows that the model effectively captures the relationships between variables without overfitting.The Root Mean Square Error (RMSE) was 2.03, indicating the average difference between predicted and actual values. The relatively low RMSE value suggests that the model provides reasonably accurate predictions.The results highlight that numeric_grade and sample_size are particularly important in predicting support levels, with larger and higher-quality polls offering more reliable estimates. The transparency score and state-level coefficients further provide insight into regional differences and the role of trust in polling, helping us better understand the dynamics behind Trump's public support.The coefficients for numeric_grade and sample_size underline the importance of poll quality and sample size in predicting support levels. Larger, higher-quality polls offer more robust estimates. Additionally, transparency and state effects provide insight into regional differences and trust factors affecting polling results, giving a clearer understanding of the dynamics influencing Trump's public support.

## Predicted Electoral Outcomes
We employed a regression model to estimate the percentage of votes Trump is likely to receive in each state. Using these predicted results and the electoral vote allocations, we identified the winner for each state and calculated the total electoral votes for both Trump and Harris.

The following table（@predictiontable） presents a summary of the predictions, including Trump’s estimated percentage, the number of electoral votes in each state, and the projected winner. For instance:

 • In Arizona, Trump is expected to receive 48.94% of the vote, resulting in a win for Harris with 11 electoral votes.
 • In Missouri, Trump is projected to receive 51.64%, thereby winning all 10 electoral votes for that state.
 • In Ohio, with an estimated 51.98% of the vote, Trump secures Ohio’s 18 electoral votes.

Electoral Vote Count: Trump Electoral Votes: 98 - Harris Electoral Votes: 239. This indicates that Harris is projected to win the 2024 U.S. Presidential Election with 239 electoral votes, while Trump is projected to gather 98. These results hinge on the outcomes in various battleground states, with several being extremely close.
```{r predictiontable}
#| echno: false
#| label: predictiontable
#| tbl-cap: Prediction for Trump and Harris by Electoral College
#| echo: false
#| warning: false
#| message: false

# Load test data
analysis_data_test <- read_parquet(here::here("data/02-analysis_data/test_data.parquet"))
analysis_data_train <- read_parquet(here::here("data/02-analysis_data/train_data.parquet"))

# Get the unique state names from training and test data
unique_states_train <- unique(analysis_data_train$state)
unique_states_test <- unique(analysis_data_test$state)


# Find common states between training and test data and filter test data to only keep these states
common_states <- intersect(unique_states_train, unique_states_test)
analysis_data_test <- analysis_data_test %>%
  filter(state %in% common_states)

# Define the number of electoral votes for each state
electoral_votes <- data.frame(
  state = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida",
            "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", 
            "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", 
            "Missouri", "Montana", "Nebraska", "Nevada", 
            "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", 
            "Oklahoma", "Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota", "Tennessee", 
            "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming", 
            "District of Columbia"),
  electoral_votes = c(9, 3, 11, 6, 55, 9, 7, 3, 29, 16, 4, 4, 20, 11, 6, 6, 8, 8, 4, 10, 11, 15, 10, 6, 10, 
                      3, 10, 6, 4, 14, 5, 29, 16, 3, 18, 7, 6, 20, 4, 9, 3, 11, 38, 6, 3, 13, 12, 5, 10, 3, 3))
# Convert methodology column to character type for recoding
analysis_data_test$methodology <- as.character(analysis_data_test$methodology)

# Recode the 'Email' level in the methodology column to 'Online Panel'
analysis_data_test$methodology[analysis_data_test$methodology == "Email"] <- "Online Panel"





# Use the trained regression model to predict Trump's support percentage in each state
analysis_data_test$predicted_percent_trump <- predict(model2, newdata = analysis_data_test)
analysis_data_test$predicted_percent_trump
total_trump <- aggregate(predicted_percent_trump ~ state, data = analysis_data_test, FUN = mean)




# Determine the winner in each state based on Trump's predicted percentage
state_predictions <- merge(total_trump, electoral_votes, by = "state")

# Determine the winner in each state based on Trump's predicted percentage
state_predictions$winner <- ifelse(state_predictions$predicted_percent_trump > 50, "Trump", "Harris")

# Calculate the electoral votes for each candidate
state_predictions$trump_electoral_votes <- ifelse(state_predictions$winner == "Trump", state_predictions$electoral_votes, 0)
state_predictions$harris_electoral_votes <- ifelse(state_predictions$winner == "Harris", state_predictions$electoral_votes, 0)

# Summarize the total electoral votes for each candidate
trump_electoral_votes <- sum(state_predictions$trump_electoral_votes)
harris_electoral_votes <- sum(state_predictions$harris_electoral_votes)

# Create and display the results table

kable(state_predictions[, c("state", "predicted_percent_trump", "electoral_votes", "winner")], 
      col.names = c("State", "Trump Predicted %", "Electoral Votes", "Winner"), 
      digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  scroll_box(width = "100%", height = "400px")


print(paste("Trump Electoral Votes:", trump_electoral_votes))
print(paste("Harris Electoral Votes:", harris_electoral_votes))
```


## Prediction map
The following map (Figure 6) displays the predicted outcome for each state in the 2024 U.S. Presidential Election, with green representing states where Trump is expected to win and blue for those where Harris is predicted to prevail.
```{r}
#| echno: false
#| label: fig-statemap
#| tbl-cap: Predicted Winner of 2024 US Presidential Election by State
#| echo: false
#| warning: false
#| message: false

# Replace NA values in the 'winner' column with 'Trump'
#state_predictions$winner[is.na(state_predictions$winner)] <- "Trump"

# "red" for Trump and "blue" for Harris
state_predictions$winner_color <- ifelse(state_predictions$winner == "Trump", "green", "blue")

# Create a map visualization showing the predicted winner by state
plot_usmap(data = state_predictions, values = "winner_color", regions = "states") +
  scale_fill_manual(values = c("green" = "green", "blue" = "blue"), name = "Predicted Winner", labels = c("Harris", "Trump")) +
  labs(title = "Predicted Winner of the 2024 U.S. Presidential Election by State") +
  theme(legend.position = "right")

```
The map illustrates Trump gaining traction across central and southern states, including Texas and Missouri, which have traditionally leaned Republican. Meanwhile, Harris holds a solid lead in states along the West Coast and in the Northeast, such as California and New York, regions that have a history of Democratic support.

Several battleground states, including Florida and Ohio, are projected to favor Trump, with a slight advantage that marks a contrast to Harris's stronger leads in places like California. The map also shows a number of central states in gray, reflecting either a lack of definitive prediction or insufficient data. Overall, the map reveals distinct regional patterns, with Trump expected to perform well in the heartland and Harris finding support along the coasts. The outcome may hinge on the final results in the competitive states like Pennsylvania, Arizona, and North Carolina.











Our results are summarized in @tbl-modelresults.








# Discussion {#sec-discussion}

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}

# Pollster Methodology Overview and Evaluation
## Overview of Siena/NYT
Siena College Research Institute (SCRI) and The New York Times launched a collaborative political poll in July 2013. Siena/NYT  was known for its rigorous methodology and accuracy, which provided its first real-time midterm election poll in 2018.In 2024, FiveThirtyEight named it the most accurate pollster in the United States. The polling methodology emphasizes live phone interviews and representative sampling and focuses on transparency and statistical accuracy to provide a deep understanding of voter sentiment.

## Target Population, Frame, and Sample
* Target Population: Registered voters or likely voters in the United States, especially voters in major battleground states during an election in 2024.\
* Sample Frame: U.S. registered voters based on a national voter file maintained by L2, with a cell phone number that matches the voter file.\
* Sample Size: Sample sizes vary across different polls. The poll in late October 2024 surveyed over 2,500 voters, and 2,097 of them completed the full survey. The margin of error for likely voters is about ±2.2 percentage points.

## Sample Recruitment
The sample was conducted by live telephone interviews in both English and Spanish. Over 98% of respondents were contacted by telephone.

## Sampling Approach and Trade-offs
Siena/NYT used a stratified sampling method. Polls were stratified by demographic characteristics such as political party, race and region. This improves accuracy but adds cost and complexity. It also makes it challenging to reach certain populations such as young voters.\

**Advantages of stratified sampling:**\

* Generates a representative sample that captures the diverse opinions of different voter populations.\
* Helps to ensure that under-represented groups are given appropriate weighting, and reduces potential bias.\
* Provides a more accurate reflection of the wider population by stratifying on key characteristics.\

**Disadvantages of stratified sampling:**\

* Increased cost and time to complete polls, especially for live telephone interviews.\
* There are challenges in reaching specific demographic groups, such as younger voters who may be less likely to participate in the poll.\
* Reliance on weighting adjustments to correct for response discrepancies, which does not fully eliminate residual bias.

## Non-response Handling
Non-response was a key problem for Siena/NYT. The poll used weighted adjustments for demographic characteristics such as age, race, gender, education, and different political parties to address non-response bias. The weighting adjustment was used to ensure that the sample closely matches the larger population and compensates for differences in response rates across demographic groups. However, non-response can still present residual bias even with weighting, especially when certain demographic groups have been less likely to respond to survey calls.

## Questionnaire Evaluation
**Strengths:**\

* Minimize bias through the use of straightforward and non-leading questions.\
* Transparency was maintained by publishing the questions verbatim to allow for public scrutiny.\
* Bilingual interviewers ensured that respondents could participate in their preferred language (English or Spanish), which increased the participation of Spanish-speaking voters and improved the quality of respondents' answers.\

**Weaknesses:**\

* The length of the poll can lead to respondent fatigue, which affects the quality of the data and increases dropout rates.\
* It can be challenging to limit calls to less than 15 minutes, which can lead to incomplete or rushed responses, thus affecting the overall reliability of the data.\

## Conclusion
The Siena/NYT poll uses stratified sampling and live phone interviews to reach a representative sample of voters. While the use of composite weighting and bilingual interviews provides advantages such as transparency and reduced bias, challenges remain including high costs and the potential for bias due to non-response. Despite these drawbacks, Siena/NYT's commitment to transparency and rigorous methodology makes it a reliable source for understanding voter sentiment and opinion.\


# Idealized Methodology and Survey
## Overview
The objective of this survey is to predict voter sentiment in the upcoming U.S. presidential election, by using a budget of $100,000 to collect accurate and varied data on voting intentions, candidate favourability, and key issues from a representative sample of registered or likely voters across the United States. The methodology is designed to maximize accuracy, minimize bias and take into account a variety of demographic, geographic and political factors that influence voting behaviour.

## Sampling Approach
The sampling approach is designed to increase coverage and ensure that a representative voting population is covered. This will be achieved by using a combination of stratified random sampling and quota sampling of key demographics.

### Stratification Variables 
* Age: 18-29, 30-44, 45-64, 65+\
* Gender: Male and Female\
* Race: White, Black /African American, Hispanic/Latino, Asian, Native and Other\
* Education level: High School, Some College, Bachelor's Degree, Graduate Degree, Other\
* Geographic region: Northeast, Midwest, South, West\
* Political Party: Democratic, Republican, Independent, Other\

### Sample Size
The target sample size was 10,000 respondents, which are stratified by the Stratification Variables described above. This stratification ensures that all major voter groups are proportionately represented. 10,000 samples have a margin of error of about ±1% and a confidence level of 95%, which is appropriate for predicting elections.

## Recruitment Strategy
The recruitment strategy was separated into two main approaches to ensure a diverse and representative sample:

**Online Survey panels:**\

* Work with established survey panels such as Lucid or YouGov.\
* These panels have access to large representative databases of voters.\
* Recruiting through panels ensures quality and reliability, as they have built-in validation and quality control processes.\

**Social Media Advertising:**\

* Use social media platforms such as Facebook, Instagram and LinkedIn to reach potential respondents.\
* Target groups that are underrepresented in traditional panels, including young voters and minority groups.\
* Social media ads will be customized with demographic information to increase reach and participation.\

**Incentives:** Offer gift card lottery prizes to all participants to encourage participation and ensure a high response rate.

## Data validation and quality control
To maintain the integrity of the data, we will take the following measures:\

* **Attention Checks:** At least two ‘attention check’ questions will be included in the survey to identify inattention or robots.\
* **Duplicate Detection:** Use email or IP-based verification to prevent duplicate responses. Ensure that each respondent provides only one response set to keep the dataset unique.\
* **Response Time Monitoring:** Track the time it takes respondents to complete surveys. Responses with apparently faster-than-average completion times are labelled as potentially low-quality.\
* **Data Consistency Check:** Analyses the consistency of responses, especially between related questions. Inconsistent answers will be labelled for review.\
* **Panel partner validation:** For respondents recruited through an online survey panel, rely on the panel provider's in-built validation systems. These systems use various quality checks, such as identity verification and response consistency, which ensure high-quality data from panel participants.


## Poll aggregation and forecasting
### Poll aggregation
* ‘Poll of polls’ approach: Survey data will be combined with data from some reliable polling sources such as Lucid, YouGov and others. This approach aggregates the results of multiple reputable polls to improve the forecast reliability by reducing bias and individual polling errors.\
* Weighting adjustments: Polls are weighted according to sample quality, size, repeatability, and demographic match. Demographic mismatches are adjusted using raking to ensure that the aggregated data accurately represents the U.S. population.

### Forecasting Method
* Bayesian modelling: Aggregate polling data is combined with historical electoral trends and demographic information using Bayesian statistical models. This approach allows for dynamic updating as new data becomes available, which improves accuracy. \
* Uncertainty Quantification: Includes confidence intervals to express uncertainty in forecasts for a more detailed interpretation. 

## Budget Allocation
* Survey Panel Recruitment: $50,000\
* Social Media Advertising: $50,000\
* Incentives(lottery prizes): $15,000\ 
* Data Cleaning and Validation: $5,000\
* Poll Aggregation and Modeling: $10,000


## Survey Implementation
The survey will be available via Google Forms to ensure broad accessibility and easy data collection. The link to the survey will be distributed via email invitations to panellists and targeted social media adverts. To ensure maximum reach and diversity, multiple channels will be used, including Facebook, Instagram, and other social media platforms. The link to the survey is [here](https://forms.gle/y4Xh2oQ544DYcCXWA).\

**Distribution Plan:**\

* **Panel invitations:** Members of established survey panels (e.g. Lucid, YouGov) will receive email invitations to participate in the survey.\
* **Social media activities:** Targeted adverts will be placed on social media platforms to reach under-represented groups, especially young voters and national minority groups.\
* **Follow-up reminders:** An automated reminder email will be sent to participants who have not completed the survey to maximize response rates.\
* **Survey Monitoring:** Response rates will be closely monitored throughout the data collection period and sampling methods will be adjusted if certain population quotas are not reached.\
* **Accessibility:** The survey will be mobile-friendly, which will allow respondents to complete the survey on any device.


## Survey Structure
**Survey Introduction:**\
Welcome! We are surveying to better understand voter preferences and priorities for the upcoming U.S. presidential election. Your participation is important and your answers will help us accurately predict the outcome of the election. It will take approximately 10 minutes to complete the survey. All responses are confidential and will be used for research purposes only.\
If you have any questions or concerns, please feel free to contact our research team at [winniekeai23@gmail.com](mailto:winniekeai23@gmail.com) (Ziyuan Shen, Leo Liu, Dezhen Chen).\
As a thank you for your participation, you will be entered into a raffle to win a grand prize of a gift card. We are deeply grateful for your participation and appreciate the time and effort that you put in.\

**Survey Question:**\

**Part 1: Screening for eligibility**\
1.Are you an eligible U.S. citizen?\
* Yes / No\
2.Are you currently 18 years of age or older?\
* Yes / No
3.Have you completed your registration to become a voter?\
* Yes / No / Plan to register\

**Part 2: Demographics**\

4.What is your age?\
* 18-24 / 25-34 / 35-44 / 45-54 / 55+\
5.What is your gender?\
* Male / Female / Non-binary / Prefer not to say\
6.Which of the following best describes your education level?\
* High School / Some College / Bachelor's Degree / Graduate Degree / Other\
7.Which region of the U.S. do you currently reside in?\
* Northeast / Midwest / South / West\    
8.Do you generally identify with a political party?\
* Democratic / Republican / Independent / None\

**Part 3: Voting Intentions**\

9.How likely are you to participate in the upcoming presidential election?\
* Very Likely / Somewhat Likely / Not Sure / Unlikely / Very Unlikely\
10.If the presidential election were held today, for which candidate would you vote?\
* Kamala Harris (Democrat) / Donald Trump (Republican) / Undecided / Prefer not to say\
11.What are the top three issues that will influence your vote?\
* Economy / Healthcare / Education / Gun Policy / Taxes / Foreign Policy / Social Security / Civil Rights / Technology / Privacy / Other[text]\

**Part 4: Information Sources and Engagement**\

12.Which of the following sources do you rely on most for political news and information?\
* Television News / Newspapers / Online News Websites / Social Media / Radio / Friends and Family / Other\
13.How often do you engage in discussions about political topics with friends or family?\
* Daily / Weekly / Monthly / Rarely / Never\

**Part 5: Verify**\

14.Please select 'Agree' to verify that you are paying attention.\
* Agree / Disagree\
15.Do you agree to participate in this survey? Your responses will be kept confidential and used only for research purposes.\
* Yes / No\

**End Part:**\
Thank you for your participation!\
Your responses are valuable to us in anticipating the upcoming election and understanding voters' priorities. If you have any questions or would like more information about our research, please feel free to contact us at [winniekeai23@gmail.com](mailto:winniekeai23@gmail.com)(Ziyuan Shen, Leo Liu, Dezhen Chen).













# Additional data details

# Model details 
```{r}
# Generate diagnostic plots for model2
par(mfrow = c(2, 2))
plot(model2)

# Generate pairwise scatter plots for all predictor variables
pairs(analysis_data_train[, c("numeric_grade", "duration", "sample_size", "transparency_score")])

```
```{r}

#  AIC 和 BIC
AIC_value <- AIC(model2)
BIC_value <- BIC(model2)


print(paste("AIC: ", AIC_value))
print(paste("BIC: ", BIC_value))


```


## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

```



\newpage


# References


